{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load crawler_v10x2.py\n",
    "\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from urllib.parse import urlencode\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import time\n",
    "import re\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "# 自定義的Error class\n",
    "class CmpyinfoCrawlerError(Exception):\n",
    "    # 起始時間sta統一由別人給，但每次會自動抓出end時間，得到目前程式執行多久了\n",
    "    def __init__(self, prefix, sta=0):\n",
    "        self.sta = sta\n",
    "        self.end = time.time()\n",
    "        self.exe = self.end - self.sta\n",
    "        self.prefix = prefix\n",
    "            \n",
    "    # 印出錯誤訊息之前順便抓一下時間，時間為執行時間\n",
    "    def __str__(self):\n",
    "        def timestr(t):\n",
    "            d, r = divmod(t, 86400)\n",
    "            h, r = divmod(r, 3600)\n",
    "            m, s = divmod(r, 60)\n",
    "            return \"{} days {:02}:{:02}:{:.2f}\".format(d, h, m, s)\n",
    "        \n",
    "        s = self.prefix + \" raised at {} \".format(timestr(self.end-self.sta))\n",
    "        return s\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "# 自定義的proxypool模組\n",
    "import proxypool\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "# 自定義的log class雖然會記錄資訊，但實際使用時不太會看\n",
    "class back_log:\n",
    "    def __init__(self, flush=False, flush_threshold=1000, first_line='',log_format='', fname =''):\n",
    "        # self.queue：用來記錄log\n",
    "        # self.flush：用來判斷是否要將self.queue的所有紀錄寫到檔案\n",
    "        # self.flush_threshold：記錄幾筆log之後要寫到檔案\n",
    "        # self.format：設定寫入log string format\n",
    "        # self.first_line：log的第一行，通常是欄位名稱\n",
    "        self.queue = list()\n",
    "        self.flush = flush\n",
    "        self.flush_threshold = flush_threshold\n",
    "        self.first_line = first_line\n",
    "        self.log_format = log_format\n",
    "        self.fname = fname\n",
    "        with open(fname, 'a') as log_file:\n",
    "            if self.first_line:\n",
    "                log_file.write(self.first_line + '\\n')\n",
    "        \n",
    "    # 透過mode來切換log格式，預設為format，或者個人也可以手動決定log格式\n",
    "    # 所有log後面皆有後綴字串postfix可以掛上\n",
    "    def log(self, mode='format', args = tuple(), in_log='', postfix=''):\n",
    "        if mode == 'format':\n",
    "            log_str = self.log_format.format(*args) + ' ' + postfix\n",
    "        elif mode == 'manual':\n",
    "            log_str = in_log + ' ' + postfix\n",
    "                \n",
    "        self.queue.append(log_str)\n",
    "        \n",
    "        if len(self.queue) >= self.flush_threshold:\n",
    "            log_str = '\\n'.join(self.queue)\n",
    "            self.log_flush()\n",
    "            \n",
    "    # 要強制寫入log檔時呼叫self.log_flush()，通常是靠self.flush是否為True來判斷要不要呼叫self.log_flush()\n",
    "    # 執行後會將self.flush設成False\n",
    "    def log_flush(self):\n",
    "        if self.queue:\n",
    "            log_str = '\\n'.join(self.queue)\n",
    "            with open(self.fname, 'a') as log_file:\n",
    "                log_file.write(log_str + '\\n')\n",
    "            \n",
    "            self.flush = False\n",
    "            \n",
    "            del self.queue\n",
    "            self.queue = list()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# 爬蟲主體\n",
    "# 查詢動作會有2階段\n",
    "# phase 1：first_connection()會將查詢關鍵字丟進去，選好搜尋的類別，然後開始搜尋，搜尋結果有時會有多頁，例如搜尋「公司」這個字串，會有100多萬筆\n",
    "# phase 2：second_connection()針對phase 1的結果，去點「詳細資料」並解析table中不同欄位的資料\n",
    "class cmpyinfo_crawler:\n",
    "    #proxies = [{'http':'http://proxy.hinet.net:80'}, {'http':'172.103.3.156:53281'}]\n",
    "    # 根據「查詢結果」的「詳細資料」頁面，表格左上角的名稱來分類，有以下幾類Cmpy, CmpyCnRp, CmpyCn, CmpyFrgnRp, CmpyFrgn, Busm, BrBusm, Fact, BrCmpy, Lmtd, BrLmtd\n",
    "    # 以上這幾類的欄位各有不同\n",
    "    h3_dict = {\n",
    "        '公司基本資料':'Cmpy',\n",
    "        '大陸公司許可報備基本資料':'CmpyCnRp', # 53656300 \n",
    "        '大陸公司許可基本資料':'CmpyCn',# 53026057\n",
    "        '外國公司報備基本資料':'CmpyFrgnRp', # 16747659\n",
    "        '外國公司認許基本資料':'CmpyFrgn', # 24812289\n",
    "        '商業登記基本資料':'Busm',\n",
    "        '商業登記基本資料(分支機構)':'BrBusm', # 02284257\n",
    "        '工廠基本資料':'Fact', \n",
    "        '分公司資料':'BrCmpy',\n",
    "        '有限合夥登記基本資料':'Lmtd',\n",
    "        '有限合夥登記基本資料(分支機構)':'BrLmtd'\n",
    "    }\n",
    "    \n",
    "    # 查詢動作共兩個：\n",
    "    # 1.先輸入查詢的字串，解析response後會有objectId\n",
    "    # 2.再根據objectId的前2碼('HC', 'HB'...)去查詢「詳細資料」，不同種類會連到不同的「詳細資料」網頁查詢\n",
    "    url2_dict = {\n",
    "        'HC' : 'http://findbiz.nat.gov.tw/fts/query/QueryCmpyDetail/queryCmpyDetail.do',\n",
    "        'HB' : 'http://findbiz.nat.gov.tw/fts/query/QueryBusmDetail/queryBusmDetail.do',\n",
    "        'BB' : 'http://findbiz.nat.gov.tw/fts/query/QueryBusmDetail/queryBusmDetail.do',\n",
    "        'HF' : 'http://findbiz.nat.gov.tw/fts/query/QueryFactDetail/queryFactDetail.do',\n",
    "        'BC' : 'http://findbiz.nat.gov.tw/fts/query/QueryBrCmpyDetail/queryBrCmpyDetail.do',\n",
    "        'HL' : 'http://findbiz.nat.gov.tw/fts/query/QueryLmtdDetail/queryLmtdDetail.do',\n",
    "        'BL' : 'http://findbiz.nat.gov.tw/fts/query/QueryLmtdDetail/queryLmtdDetail.do'\n",
    "    }\n",
    "    \n",
    "    # objectId前2碼與網站中form_data類別的對應\n",
    "    cmpy_type_dict = {\n",
    "        'HC' : 'Cmpy',   # 公司\n",
    "        'HB' : 'Busm',   # 商業\n",
    "        'BB' : 'Busm',   # 商業\n",
    "        'HF' : 'Fact',   # 工廠\n",
    "        'BC' : 'BrCmpy', # 分公司\n",
    "        'HL' : 'Lmtd',   # 有限合夥\n",
    "        'BL' : 'BrLmtd'  # 有限合夥分公司\n",
    "    }\n",
    "    # 使用 UserAgent套件，以隨機產生request header的user agent\n",
    "    ua = UserAgent()\n",
    "    \n",
    "    #proxy = proxypool()\n",
    "    \n",
    "    def __init__(self, qryCond='', qryType='', pageStart=1, pageEnd=1, path_phantomjs = '/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs', logname = 'task.log', sleep_scale='small'):\n",
    "        \n",
    "        # self.path_phantomjs ： phantomjs執行檔路徑\n",
    "        # self.session        ： session\n",
    "        # self.pageStart      ： 當phase 1的結果為多頁，設定要從哪一頁開始爬，目前系統上限能爬的內容為500頁\n",
    "        # self.pageNow        ： 針對phase 1的多頁結果爬到第幾頁\n",
    "        # self.pageEnd        ： phase 1的多頁結果最多爬到第幾頁\n",
    "        # self.pageItem       ： 預設phase 1的結果每頁至多20項，self.phageItem紀錄現在是第幾項\n",
    "        # self.qryCond        ： 要查詢的關鍵字\n",
    "        # self.qryType        ： 搜尋的種類，相當於對搜尋頁面中「公司」、「商業」、「工廠」、「分公司」、「有限合夥」核取方塊打勾        \n",
    "        self.path_phantomjs = path_phantomjs\n",
    "        self.session = None\n",
    "        self.pageStart = pageStart \n",
    "        self.pageNow = pageStart\n",
    "        self.pageEnd = pageEnd\n",
    "        self.pageItem = 1 \n",
    "        self.qryCond = qryCond\n",
    "        self.qryType = qryType\n",
    "        \n",
    "        # 以下是phase 2時要送的form_data\n",
    "        # 都必須透過解析phase 1的response來得到，特別是透過phase 1得到的objectId前兩碼來填入對應的值\n",
    "        # 參：self.get_banKey_objectId()\n",
    "        # self.banNo      ：phase 2要用到的form data，依objectId前兩碼而異\n",
    "        # self.brBanNo    ：phase 2要用到的form data，依objectId前兩碼而異\n",
    "        # self.banKey     ：phase 2要用到的form data，依objectId前兩碼而異\n",
    "        # self.estbId     ：phase 2要用到的form data，依objectId前兩碼而異\n",
    "        # self.objectId   ：objectId\n",
    "        # self.objectId64 ：v.1.10之後ojbectId解析出來還會經過base64編碼，要送出去的object也要經過base64編碼才能成功騙過server\n",
    "        # self.querytype  ：phase 1可能會有多筆結果，針對每一筆的objectId可以取出前兩碼，self.querytype是用來存objectId前兩碼，並針對這兩碼來決定要送出的form data要長怎樣        \n",
    "        self.banNo = None\n",
    "        self.brBanNo = None\n",
    "        self.banKey = None\n",
    "        self.estbId = None\n",
    "        self.objectId = None\n",
    "        self.objectId64 = None\n",
    "        self.querytype = None\n",
    "        \n",
    "        # self.cookie        ：後來沒用到\n",
    "        # self.oncontextmenu ：phase 1每一頁若有多筆結果，則結果會存在response的oncontextmenu，我們透過這個list來存phase 1某頁的所有查詢結果\n",
    "        # self.h3_info       ：後來沒用到\n",
    "        # self.response      ：收到的response，除了拿來parse之外，主要是debug用\n",
    "        # self.h3_text       ：phase 2時，詳細資料內會有某些特定的文字（即self.h3_dict的key），依照不同的文字可以分成幾大類\n",
    "        # self.h3_query      ：對應self.h3_dict[self.h3_text]得到的value，主要是內部做parsing時會按照self.h3_query當作規則\n",
    "        # self.user_agent    ：header的user_agent\n",
    "        self.cookie = None\n",
    "        self.oncontextmenu = list()\n",
    "        self.h3_info = defaultdict(set)\n",
    "        self.response = None\n",
    "        self.h3_text = None\n",
    "        self.h3_query = None\n",
    "        self.user_agent = None\n",
    "\n",
    "        \n",
    "        # self.sta            ：開始執行時間\n",
    "        # self.end            ：結束執行時間\n",
    "        # self.this_round_sta ：phase 1的多頁結果，每一頁起始的時間\n",
    "        # self.this_round_end ：phase 1的多頁結果，每一夜的結束時間，跟self.this_round_sta相減可以得到處理時間\n",
    "        # self.pooling        ：單位為秒，self.proxy_monitor()會根據這個值決定何時要換proxy，設為<0的值則不會換proxy\n",
    "        self.sta = time.time()\n",
    "        self.end = time.time()\n",
    "        self.this_round_sta = time.time()\n",
    "        self.this_round_end = time.time()\n",
    "        self.pooling = time.time()\n",
    "        \n",
    "        \n",
    "        # self.proxypool    ：proxypool物件\n",
    "        # self.proxy_ratio  ：proxy每N筆切回None(用自己ip)\n",
    "        # self.proxy_i      ：後來沒用到\n",
    "        # self.proxy        ：現在拿到的proxy\n",
    "        # self.proxy_update ：換了proxy後會設為True，用來判斷做不同處理(例如session要重開)\n",
    "        # self.proxy_tick   ：self.proxy_monitor()多久換一次proxy\n",
    "        self.proxypool = proxypool.proxypool(path_phantomjs=path_phantomjs)\n",
    "        self.proxy_ratio = 5 # 5 proxies vs 1 None\n",
    "        self.proxy_i = 0\n",
    "        self.proxy = None\n",
    "        self.proxy_update = True\n",
    "        self.proxy_tick = 1800\n",
    "\n",
    "        # resolve_page\n",
    "        # self.totalPage        ：phase 1的結果會有「共n筆、共m頁」的字樣，self.totalPage用來記錄phase 1的結果有幾頁\n",
    "        # self.totalCount       ：phase 1的結果會有「共n筆、共m頁」的字樣，self.totalPage用來記錄phase 1的結果有幾筆\n",
    "        # self.flush_threshold  ：設定蒐集到結果每幾筆要寫出到檔案中，現在設定20筆，就是phase 1結果每一頁的最多筆數\n",
    "        # self.total_json_name  ：寫出的juson檔名\n",
    "        # self.search_error_cnt ：正常來說有時搜尋的統編查不到資料，但也有可能是proxy問題，設定一直出現search_error幾次才真的跳過\n",
    "        self.totalPage = 1\n",
    "        self.totalCount = 1\n",
    "        self.flush_threshold = 20\n",
    "        self.total_json_name = \"all_json_out\"\n",
    "        self.search_error_cnt = 0\n",
    "        \n",
    "        \n",
    "\n",
    "        def tasklog_timestamp():\n",
    "            d = datetime.now()\n",
    "            d.year,d.month,d.day,d.hour,d.minute,d.second\n",
    "            nowstr = \"{0:0>4d}{1:0>2d}{2:0>2d}_{3:0>2d}{4:0>2d}{5:0>2d}\".format(d.year,d.month,d.day,d.hour,d.minute,d.second)\n",
    "            return nowstr   \n",
    "            \n",
    "            \n",
    "        self.timestamp = tasklog_timestamp()\n",
    "        self.tasklog = back_log(flush=False, \n",
    "                                flush_threshold=100, \n",
    "                                first_line='{0: >19s}, {1: >19s}, {2: >6s}, {3: >6s}'.format('task execution time', 'this round time', 'page', 'item'), \n",
    "                                log_format= '{0: >19s}, {1: >19s}, {2: >6d}, {3: >6d}', \n",
    "                                fname = '{}@{: >17s}.task.log'.format(logname, str(self.timestamp)))\n",
    "        self.parser = {'Cmpy':parser_cmpy_type('Cmpy', self.tasklog), \n",
    "                       'CmpyFrgnRp':parser_cmpy_type('CmpyFrgnRp', self.tasklog), \n",
    "                       'CmpyFrgn':parser_cmpy_type('CmpyFrgn', self.tasklog), \n",
    "                       'CmpyCnRp':parser_cmpy_type('CmpyCnRp', self.tasklog), \n",
    "                       'CmpyCn':parser_cmpy_type('CmpyCn', self.tasklog), \n",
    "                       'BrCmpy':parser_cmpy_type('BrCmpy', self.tasklog), \n",
    "                       'Busm':parser_cmpy_type('Busm', self.tasklog), \n",
    "                       'BrBusm':parser_cmpy_type('BrBusm', self.tasklog), \n",
    "                       'Fact':parser_cmpy_type('Fact', self.tasklog),\n",
    "                       'Lmtd':parser_cmpy_type('Lmtd', self.tasklog), \n",
    "                       'BrLmtd':parser_cmpy_type('BrLmtd', self.tasklog)}\n",
    "        \n",
    "        self.tr = dict()\n",
    "        self.trlog = dict()\n",
    "        self.objidlog = dict()\n",
    "        \n",
    "        self.results = defaultdict(list)\n",
    "        #self.flush_threshold = 20;\n",
    "        \n",
    "        self.exception_happened = False\n",
    "        self.sleep_scale = sleep_scale \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        #attr = {\"session\":self.session, \"qryCond\":self.qryCond, \"banNo\":self.banNo, \"brBanNo\":self.brBanNo, \"banKey\":self.banKey, \"estbId\":self.estbId, \"objectId\":self.objectId, \"querytype\":self.querytype, \"cmpy_type\":self.cmpy_type, \"h3_text\":self.h3_text}\n",
    "        attr = {\"session\":self.session, \"qryCond\":self.qryCond, \"banNo\":self.banNo, \"brBanNo\":self.brBanNo, \"banKey\":self.banKey, \"estbId\":self.estbId, \"objectId\":self.objectId, \"querytype\":self.querytype, \"h3_text\":self.h3_text, \"h3_query\":self.h3_query}        \n",
    "        return str(attr) + \" \" + self.exectime('task execution time: ')\n",
    "\n",
    "    def timestr(self, t):\n",
    "        d, r = divmod(t, 86400)\n",
    "        h, r = divmod(r, 3600)\n",
    "        m, s = divmod(r, 60)\n",
    "        return \"{: >4d} days {: >2d}:{: >2d}:{: >2d}\".format(int(d), int(h), int(m), int(s))\n",
    "    \n",
    "    def exectime(self, prefix = ''):\n",
    "        # task execution time\n",
    "        self.end = time.time()\n",
    "        return prefix + self.timestr(self.end - self.sta)\n",
    "        \n",
    "    def this_round_time_start(self):\n",
    "        self.this_round_sta = time.time()\n",
    "    \n",
    "    #def this_round_time_end(self):\n",
    "    #    self.this_round_end = time.time()\n",
    "    \n",
    "    def this_round_exectime(self, prefix = ''):\n",
    "        # page execution time\n",
    "        self.this_round_end = time.time()\n",
    "        return prefix + self.timestr(self.this_round_end - self.this_round_sta)\n",
    "\n",
    "    def get_banKey_objectId(self, attri):\n",
    "        def objectId_base64(objectId):\n",
    "            import base64\n",
    "            b_objectId = str.encode(objectId) # str to byte str\n",
    "            encoded_b_objectId = base64.b64encode(b_objectId)\n",
    "            return encoded_b_objectId.decode('utf8')\n",
    "            \n",
    "        # 必須透過objectId來決定要如何填入header\n",
    "        self.objectId = (attri.replace(\"javascript:qryDetail('\",\"\")).replace(\"', true);return false;\",\"\")\n",
    "        self.objectId64 = objectId_base64(self.objectId)\n",
    "        self.querytype = self.objectId[0:2]\n",
    "        #self.cmpy_type = cmpyinfo_crawler.cmpy_type_dict[self.querytype]\n",
    "        \n",
    "        try:\n",
    "            if self.querytype not in cmpyinfo_crawler.url2_dict:\n",
    "                raise CmpyinfoCrawlerError('QueryTypeError', self.sta)\n",
    "        except CmpyinfoCrawlerError as ccerr:\n",
    "            print(ccerr)\n",
    "            return       \n",
    "                  \n",
    "\n",
    "        # 按照objectId[0:2]來決定如何填入header\n",
    "        if self.querytype == 'HC': # 公司\n",
    "            self.banNo = self.objectId.replace('HC', '')\n",
    "            self.brBanNo = ''\n",
    "            self.banKey = ''\n",
    "            self.estbId = ''\n",
    "        elif self.querytype == 'BC': # 分公司\n",
    "            self.banNo = ''\n",
    "            self.brBanNo = self.objectId.replace('BC', '')\n",
    "            self.banKey = ''\n",
    "            self.estbId = ''\n",
    "        elif self.querytype == 'HB': # 商號\n",
    "            self.banNo = self.objectId[2:2+8]\n",
    "            self.brBanNo = ''\n",
    "            self.banKey = self.objectId[2+8:]\n",
    "            self.estbId = ''\n",
    "        elif self.querytype == 'BB': # 商號分公司\n",
    "            self.banNo = self.objectId[2:2+8]\n",
    "            self.brBanNo = ''\n",
    "            self.banKey = self.objectId[2+8:]\n",
    "            self.estbId = ''            \n",
    "        elif self.querytype == 'HF': # 工廠\n",
    "            self.banNo = ''\n",
    "            self.brBanNo = ''\n",
    "            self.banKey = ''\n",
    "            self.estbId = self.objectId.replace('HF', '')\n",
    "        elif self.querytype == 'HL': # 有限合夥\n",
    "            self.banNo = self.objectId.replace('HL', '')\n",
    "            self.brBanNo = ''\n",
    "            self.banKey = ''\n",
    "            self.estbId = ''\n",
    "        elif self.querytype == 'BL': # 有限合夥分支\n",
    "            self.banNo = self.objectId.replace('BL', '')\n",
    "            self.brBanNo = ''\n",
    "            self.banKey = ''\n",
    "            self.estbId = ''\n",
    "\n",
    "    \n",
    "        #print('banNo:', self.banNo, 'brBanNo:', self.brBanNo, 'banKey:', self.banKey, 'estbId:', self.estbId, 'querytype:', self.querytype)\n",
    "        \n",
    "    def first_connection_header0(self):\n",
    "        self.form_data_url1 = dict()\n",
    "        self.form_data_url1 = {'qryCond':str(self.qryCond),\n",
    "                               'infoType':'D',\n",
    "                               'qryType':'',\n",
    "                               'cmpyType':'',\n",
    "                               'brCmpyType':'',\n",
    "                               'busmType':'',\n",
    "                               'factType':'',\n",
    "                               'lmtdType':'',\n",
    "                               'isAlive':'all',\n",
    "                               'sugCont':'',\n",
    "                               'sugEmail':'',\n",
    "                               'g-recaptcha-response':''\n",
    "                              }\n",
    "        #if len(self.qryType) > 1:\n",
    "        #    self.form_data_url1['isAlive'] = 'all'\n",
    "        #else:\n",
    "        #    self.form_data_url1['isAlive'] = 'true'\n",
    "        \n",
    "        for qry in self.qryType:\n",
    "            if qry == 'cmpyType':\n",
    "                self.form_data_url1['qryType'] = 'cmpyType'\n",
    "                self.form_data_url1['cmpyType'] = 'true'\n",
    "            if qry == 'brCmpyType':\n",
    "                self.form_data_url1['qryType'] = 'brCmpyType'\n",
    "                self.form_data_url1['brCmpyType'] = 'true'\n",
    "            if qry == 'busmType':\n",
    "                self.form_data_url1['qryType'] = 'busmType'\n",
    "                self.form_data_url1['busmType'] = 'true'\n",
    "            if qry == 'factType':\n",
    "                self.form_data_url1['qryType'] = 'factType'\n",
    "                self.form_data_url1['factType'] = 'true'            \n",
    "            if qry == 'lmtdType':\n",
    "                self.form_data_url1['qryType'] = 'lmtdType'\n",
    "                self.form_data_url1['lmtdType'] = 'true'            \n",
    "\n",
    "    def first_connection_header1(self, currentPage):\n",
    "        self.form_data_url1 = dict()\n",
    "        self.form_data_url1 = {'pagingModel.totalCount':str(self.totalCount),\n",
    "                               'pagingModel.currentPage':str(currentPage),\n",
    "                               'pagingModel.totalPage':str(self.totalPage),\n",
    "                               'model.qryCond':str(self.qryCond),\n",
    "                               'model.isAlive':'all',\n",
    "                               'model.cmpyType':'',\n",
    "                               'model.brCmpyType':'',\n",
    "                               'model.busmType':'',\n",
    "                               'model.factType':'',\n",
    "                               'model.lmtdType':'',\n",
    "                               'model.infoType':'D',\n",
    "                               'model.busiItemSub':'',\n",
    "                               'model.city':''}        \n",
    "        \n",
    "        for qry in self.qryType:\n",
    "            if qry == 'cmpyType':\n",
    "                self.form_data_url1['model.cmpyType'] = 'true'\n",
    "            if qry == 'brCmpyType':\n",
    "                self.form_data_url1['model.brCmpyType'] = 'true'\n",
    "            if qry == 'busmType':\n",
    "                self.form_data_url1['model.busmType'] = 'true'\n",
    "            if qry == 'factType':\n",
    "                self.form_data_url1['model.factType'] = 'true'            \n",
    "            if qry == 'lmtdType':\n",
    "                self.form_data_url1['model.lmtdType'] = 'true'\n",
    "                \n",
    "    def set_form_data_url1(self, mode, currentPage=1):\n",
    "        if mode == 0:\n",
    "            self.first_connection_header0()\n",
    "        elif mode == 1:\n",
    "            self.first_connection_header1(currentPage)\n",
    "    \n",
    "    def new_session(self):\n",
    "        if self.proxy_update:\n",
    "            if self.session is not None:\n",
    "                self.session.close()\n",
    "        \n",
    "            self.session = requests.Session()\n",
    "            self.proxy_update = False    \n",
    "    \n",
    "    def first_connection(self):\n",
    "        url1 = 'http://findbiz.nat.gov.tw/fts/query/QueryList/queryList.do'\n",
    "        \n",
    "        request_header1 = {\n",
    "            'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding':'gzip, deflate',\n",
    "            'Accept-Language':'zh-TW,zh;q=0.8,en-US;q=0.6,en;q=0.4',\n",
    "            'Cache-Control':'max-age=0',\n",
    "            'Connection':'keep-alive',\n",
    "            ##'Content-Length':'239',\n",
    "            'Content-Type':'application/x-www-form-urlencoded',\n",
    "            ##'Cookie':'qryCond=00114003~type=cmpyType,brCmpyType,busmType,factType,lmtdType,~infoType=D~isAlive=all~; JSESSIONID=6D2FA44A8850268F8A6A9D429D53B548; DWRSESSIONID=*o94X5xiFwhD8b5kRGWQo7XpKTl; JSESSIONID=33352345177332F62F210E99D78BD44A; _ga=GA1.3.315276753.1502943360; _gid=GA1.3.754870603.1502943360; _gat=1',\n",
    "            'Host':'findbiz.nat.gov.tw',\n",
    "            'Origin':'http://findbiz.nat.gov.tw',\n",
    "            'Referer':'http://findbiz.nat.gov.tw/fts/query/QueryBar/queryInit.do',\n",
    "            'Upgrade-Insecure-Requests':'1',\n",
    "            #'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36'   \n",
    "        }\n",
    "        #if get_new_session:\n",
    "        \n",
    "        if self.proxy_update:\n",
    "            # 新的session 會換瀏覽器，並且拿新的session\n",
    "            request_header1['User-Agent'] = cmpyinfo_crawler.ua.random\n",
    "            # self.new_session()會將proxy_update設為False，所以要放後面\n",
    "            self.new_session()\n",
    "           \n",
    "        try:\n",
    "            self.response = self.session.post(url1, headers=request_header1, data=self.form_data_url1, proxies=self.proxy)\n",
    "            \n",
    "        except requests.exceptions.ProxyError as err:\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception requests.ProxyError @ first_connection(), remove proxy\")\n",
    "            self.change_proxy()\n",
    "            #self.response = self.session.post(url1, headers=request_header1, data=self.form_data_url1, proxies=self.proxy)\n",
    "            return False            \n",
    "        except Exception as err:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ first_connection()\")\n",
    "            print(err.__doc__)\n",
    "            self.tasklog.log(mode='manual', in_log = err.__doc__)\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            if self.response.status_code != 200:\n",
    "                raise CmpyinfoCrawlerError('Response200Error', self.sta)\n",
    "        except CmpyinfoCrawlerError as ccerr:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ first_connection()\")\n",
    "            print(ccerr)\n",
    "            self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "        except Exception as err:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ first_connection()\")\n",
    "            print(err.__doc__)\n",
    "            self.tasklog.log(mode='manual', in_log = err.__doc__)\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "\n",
    "       \n",
    "        try:\n",
    "            selector = etree.HTML(self.response.content)\n",
    "        except Exception as err:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception from etree @ first_connection()\")\n",
    "            print(err.__doc__)\n",
    "            self.tasklog.log(mode='manual', in_log = err.__doc__)\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "       \n",
    "        # reCaptcha 測試\n",
    "        try:\n",
    "            recaptcha = selector.xpath('//div[@class=\"g-recaptcha\"]')\n",
    "            if recaptcha:\n",
    "                raise CmpyinfoCrawlerError('reCaptchaError', self.sta)\n",
    "        except CmpyinfoCrawlerError as ccerr:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ first_connection()\")\n",
    "            print(ccerr)\n",
    "            self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "        except Exception as err:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception from recaptcha@ first_connection()\")\n",
    "            print(err.__doc__)\n",
    "            self.tasklog.log(mode='manual', in_log = err.__doc__)\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "\n",
    "        \n",
    "        # 同一統編可有多個結果\n",
    "        #hrefs = selector.xpath('//*[@id=\"vParagraph\"]/div[@class=\"panel panel-default\"]/div[@class=\"panel-heading companyName\"]/a')\n",
    "        hrefs = selector.xpath('//*[@id=\"vParagraph\"]/div[@class=\"panel panel-default\"]/div[2]/span')\n",
    "        del self.oncontextmenu\n",
    "        self.oncontextmenu = list()\n",
    "        for h in hrefs:\n",
    "            #if h.attrib['oncontextmenu'] not in self.oncontextmenu:\n",
    "            if 'oncontextmenu' in h.attrib and h.attrib['oncontextmenu'] not in self.oncontextmenu:\n",
    "                self.oncontextmenu.append(h.attrib['oncontextmenu'])\n",
    "\n",
    "\n",
    "        try:\n",
    "            if not self.oncontextmenu:\n",
    "                raise CmpyinfoCrawlerError('searchFailError', self.sta)\n",
    "            else:\n",
    "                return True\n",
    "        except CmpyinfoCrawlerError as ccerr:\n",
    "            self.search_error_cnt = self.search_error_cnt + 1\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ first_connection()\")\n",
    "            print(ccerr)\n",
    "            self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False                \n",
    "        except Exception as err:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception from oncontextmenu@ first_connection()\")\n",
    "            print(err.__doc__)\n",
    "            self.tasklog.log(mode='manual', in_log = err.__doc__)\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "\n",
    "               \n",
    "        \n",
    "    def second_connection(self):\n",
    "        url2 = cmpyinfo_crawler.url2_dict[self.querytype]\n",
    "        \n",
    "        form_data_url2 = {\n",
    "            'banNo':str(self.banNo),\n",
    "            'brBanNo':str(self.brBanNo),\n",
    "            'banKey':str(self.banKey),\n",
    "            'estbId':str(self.estbId),\n",
    "            'objectId':str(self.objectId64),\n",
    "            'CPage':'',\n",
    "            'brCmpyPage':'',\n",
    "            'eng':'',\n",
    "        }\n",
    "\n",
    "        request_header2={\n",
    "            'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Encoding':'gzip, deflate',\n",
    "            'Accept-Language':'zh-TW,zh;q=0.8,en-US;q=0.6,en;q=0.4',\n",
    "            'Cache-Control':'max-age=0',\n",
    "            'Connection':'keep-alive',\n",
    "            ##'Content-Length':'211',\n",
    "            ##'Content-Type':'application/x-www-form-urlencoded',\n",
    "            ##'Cookie':'JSESSIONID=3193CF8D61AEC43F3810BF07524701BA; DWRSESSIONID=*o94X5xiFwhD8b5kRGWQo7XpKTl; _gat=1; _ga=GA1.3.315276753.1502943360; _gid=GA1.3.754870603.1502943360',\n",
    "            'Host':'findbiz.nat.gov.tw',\n",
    "            'Origin':'http://findbiz.nat.gov.tw',\n",
    "            'Referer':'http://findbiz.nat.gov.tw/fts/query/QueryList/queryList.do',\n",
    "            ##'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36'\n",
    "        }\n",
    "        ua = UserAgent()\n",
    "        request_header2['User-Agent'] = cmpyinfo_crawler.ua.random\n",
    "        #self.response = self.session.post(url2, headers=request_header2,data=form_data_url2, proxies=self.proxy) # first connection有機會重新設定self.proxy, second connection直接用\n",
    "\n",
    "        try:\n",
    "            self.response = self.session.post(url2, headers=request_header2,data=form_data_url2, proxies=self.proxy) # first connection有機會重新設定self.proxy, second connection直接用\n",
    "        except requests.exceptions.ProxyError as err:\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception requests.ProxyError @ second_connection(), remove proxy\")\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "        except Exception as err:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ second_connection()\")\n",
    "            print(err.__doc__)\n",
    "            self.tasklog.log(mode='manual', in_log = err.__doc__)\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            if self.response.status_code != 200:\n",
    "                raise CmpyinfoCrawlerError('Response200Error', self.sta)\n",
    "        except CmpyinfoCrawlerError as ccerr:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ second_connection()\")\n",
    "            print(ccerr)\n",
    "            self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "            self.tasklog.log_flush()\n",
    "            self.change_proxy()\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    # 由h3解析出來的中文字串才是比較精確的類型\n",
    "    def get_h3(self):\n",
    "        selector = etree.HTML(self.response.content)\n",
    "        h3 = selector.xpath('//div[@id=\"content\"]/div[@class=\"tab-content\"]/div[@class=\"tab-pane active\"]/h3')\n",
    "        \n",
    "\n",
    "        try:\n",
    "            if len(h3) == 0:\n",
    "                raise CmpyinfoCrawlerError('h3ResolveError', self.sta)\n",
    "        except CmpyinfoCrawlerError as ccerr:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ get_h3(): can't resolve h3 in xpath\")\n",
    "            print(ccerr)\n",
    "            self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "            self.tasklog.log_flush()\n",
    "            return False\n",
    "        \n",
    "        self.h3_text = h3[0].text.encode('latin_1', errors='ignore').decode('utf8', errors='ignore')\n",
    "        self.h3_text = re.sub(r'\\s', r'', self.h3_text)\n",
    "        print('self.h3_text resolved: ', self.h3_text)\n",
    "        #print(self.h3_text)\n",
    "        if self.h3_text in cmpyinfo_crawler.h3_dict:\n",
    "            self.h3_query = cmpyinfo_crawler.h3_dict[self.h3_text]\n",
    "            print('self.h3_query resolved: ', self.h3_query)\n",
    "        \n",
    "        try:\n",
    "            if self.h3_text not in cmpyinfo_crawler.h3_dict:\n",
    "                raise CmpyinfoCrawlerError('h3ResolveError', self.sta)\n",
    "        except CmpyinfoCrawlerError as ccerr:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Exception @ get_h3(): new h3 found\")\n",
    "            print(ccerr)\n",
    "            self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "            self.tasklog.log_flush()\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "            \n",
    "\n",
    "\n",
    "    def proxy_monitor(self):\n",
    "        if self.proxy_tick < 0:\n",
    "            return\n",
    "\n",
    "        self.end = time.time()        \n",
    "        if self.end - self.pooling > self.proxy_tick:\n",
    "            self.change_proxy()\n",
    "            self.pooling = time.time()\n",
    "    \n",
    "    def renew_poroxypool(self):\n",
    "        self.proxypool.reset_proxy()\n",
    "        # 更新proxypool，先拿亞洲，拿不到就拿全世界\n",
    "        try:\n",
    "            self.proxypool.group_proxy()\n",
    "            if len(self.proxypool.proxy_set) == 0:\n",
    "                raise CmpyinfoCrawlerError('ResolveProxyError', self.sta)\n",
    "        except CmpyinfoCrawlerError as cerr:\n",
    "            self.exception_happened = True\n",
    "            self.tasklog.log(mode='manual', in_log = \"Can not resolve proxy from proxypool.group _proxy(), retry proxypool.group_proxy()\")\n",
    "            print(ccerr)\n",
    "            self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "            self.tasklog.log_flush()\n",
    "            \n",
    "            try:\n",
    "                self.proxypool.group_proxy()\n",
    "                if len(self.proxypool.proxy_set) == 0:\n",
    "                    raise CmpyinfoCrawlerError('ResolveProxyError', self.sta)                \n",
    "            except:\n",
    "                self.exception_happened = True\n",
    "                self.tasklog.log(mode='manual', in_log = \"Can not resolve proxy from proxypool.group_proxy(), you can only use local ip\")\n",
    "                print(ccerr)\n",
    "                self.tasklog.log(mode='manual', in_log = str(ccerr))\n",
    "                self.tasklog.log_flush()\n",
    "                return False\n",
    "            \n",
    "                \n",
    "        #self.proxypool.filter_proxy()\n",
    "        proxy_str = 'resolved ' + str(len(self.proxypool.proxy_set)) + ' proxies'\n",
    "        print(proxy_str)\n",
    "        self.tasklog.log(mode='manual', in_log = proxy_str)\n",
    "        return True\n",
    "\n",
    "    def set_proxy(self, p):\n",
    "        self.proxy = p\n",
    "        proxy_str = 'proxy change to ' + str(self.proxy) + ' @ ' + self.exectime('task execution time: ')\n",
    "        print(proxy_str)\n",
    "        self.tasklog.log(mode='manual', in_log = proxy_str)\n",
    "        self.proxy_update = True\n",
    "\n",
    "        \n",
    "    \n",
    "    def change_proxy(self):\n",
    "        #ratio = 5 # 5 proxies vs 1 None\n",
    "        #import random\n",
    "        #self.proxy_list = self.proxypool.proxy_list self.proxy_list[0]\n",
    "        if not self.proxypool.proxy_set:\n",
    "            self.renew_poroxypool()\n",
    "        \n",
    "        #self.proxy_i += 1\n",
    "        #if self.proxy_i % self.proxy_ratio == 0:\n",
    "        #    p = None\n",
    "        #else:  \n",
    "        #    p = {'http':self.proxypool.random_choice_one_proxy()}\n",
    "        p = self.proxypool.random_choice_one_proxy_with_none_freq()\n",
    "        \n",
    "        self.set_proxy(p)\n",
    "        #self.proxy_update = True\n",
    "        \n",
    "\n",
    "\n",
    "    def random_sleep(self, scale = 'small'):\n",
    "        import random\n",
    "\n",
    "        #            15%   20%     20%     10% 15%   20%   \n",
    "        sleeptime = [1,1,1,2,2,2,2,3,3,3,3,4,4,5,5,5,6,6,6,6]\n",
    "        #            15%               35%                  15%               15%            5%    15%   \n",
    "        magnitude = [0.75, 0.75, 0.75, 1, 1, 1, 1, 1, 1, 1, 1.25, 1.25, 1.25, 1.5, 1.5, 1.5, 1.75, 2, 2, 2]\n",
    "        #            10%20%   30%      40%\n",
    "        basetime  = [5, 7.5, 7.5, 10, 12.5, 12.5, 3, 3, 3, 3]\n",
    "        \n",
    "        if scale == 'none':\n",
    "            return\n",
    "\n",
    "        if scale == 'mixed':\n",
    "            scale = random.choice(['small']+['midium']+['large'])\n",
    "        if scale == 'mixed_small':\n",
    "            scale = random.choice(['small']*14+['midium']*3+['large']*3)\n",
    "        if scale == 'mixed_medium':\n",
    "            scale = random.choice(['small']*3+['midium']*14+['large']*3)\n",
    "        if scale == 'mixed_large':\n",
    "            scale = random.choice(['small']*3+['midium']*3+['large']*14)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        m = random.choice(magnitude)\n",
    "        b = random.choice(basetime)        \n",
    "        s = random.choice(sleeptime)\n",
    "        if scale == 'small':\n",
    "            s *= 1\n",
    "            b *= 0.25\n",
    "            m *= 0.75\n",
    "        if scale == 'midium':\n",
    "            s *= 6\n",
    "            b *= 0.75\n",
    "            m *= 0.75\n",
    "        if scale == 'large':\n",
    "            s *= 12\n",
    "            b *= 1\n",
    "            m *= 1 \n",
    "            \n",
    "        time.sleep(b+m*s)\n",
    "            \n",
    "    def print_html(self):\n",
    "        print(self.response.content.decode('utf8'))\n",
    "        \n",
    "    def resolve_page(self):\n",
    "        selector = etree.HTML(self.response.content)\n",
    "        text = selector.xpath('//*[@id=\"queryListForm\"]/div[@class=\"main\"]/div[@class=\"container padding_top\"]/div[@class=\"row\"]/div[@class=\"col-lg-12\"]/div/div/div/text()')\n",
    "        #for i, t in enumerate(text):\n",
    "        #    print(i, t.encode('latin_1').decode('utf8'))\n",
    "        text = text[1].encode('latin_1', errors='ignore').decode('utf8', errors='ignore')\n",
    "        print(text)\n",
    "        self.tasklog.log(mode='manual', in_log = 'task resolved: '+ text)\n",
    "        text = re.sub(r'[\\s共筆分頁,]', r'', text)\n",
    "        print(text)\n",
    "        self.totalCount, self.totalPage = [int(t) for t in text.split('、')]\n",
    "    \n",
    "    def h3_info_collector(self, pageStart, pageEnd):\n",
    "        item_count = 0\n",
    "        for self.pageNow in range(pageStart, pageEnd+1):\n",
    "            self.this_round_time_start()\n",
    "            if self.pageNow > 1:\n",
    "                self.set_form_data_url1(mode = 1, currentPage = self.pageNow)\n",
    "            else:\n",
    "                self.set_form_data_url1(mode = 0)\n",
    "            \n",
    "            self.proxy_monitor()\n",
    "            self.first_connection()\n",
    "\n",
    "            for self.pageItem, o in enumerate(self.oncontextmenu, 1):\n",
    "                self.get_banKey_objectId(o)\n",
    "                self.second_connection()\n",
    "                if not self.get_h3():\n",
    "                    continue\n",
    "        \n",
    "                #parser = parser_cmpy_type(self.h3_query)\n",
    "                parser = self.parser[self.h3_query]\n",
    "                \n",
    "                \n",
    "                if self.h3_text not in self.objidlog:\n",
    "                    self.objidlog[self.h3_text] = set()\n",
    "                self.objidlog[self.h3_text].add(self.objectId)\n",
    "                \n",
    "                #if len(self.objectId[self.h3_text]) >= 1000:\n",
    "                #    continue\n",
    "                \n",
    "                if self.h3_text not in self.tr:                    \n",
    "                    trset = parser.retrive_tr(self.response, set(), \n",
    "                                              {'banNo':str(self.banNo),\n",
    "                                               'brBanNo':str(self.brBanNo),\n",
    "                                               'banKey':str(self.banKey),\n",
    "                                               'estbId':str(self.estbId),\n",
    "                                               'objectId':str(self.objectId)},\n",
    "                                              {'page':str(self.pageNow),\n",
    "                                               'item':str(self.pageItem)})\n",
    "                else:\n",
    "                    trset = parser.retrive_tr(self.response, self.tr[self.h3_text],  \n",
    "                                              {'banNo':str(self.banNo),\n",
    "                                               'brBanNo':str(self.brBanNo),\n",
    "                                               'banKey':str(self.banKey),\n",
    "                                               'estbId':str(self.estbId),\n",
    "                                               'objectId':str(self.objectId)},\n",
    "                                              {'page':str(self.pageNow),\n",
    "                                               'item':str(self.pageItem)})\n",
    "                #    self.tr[self.h3_text] = set()\n",
    "                    \n",
    "                #trset = parser.retrive_tr(self.response, self.tr[self.h3_text], self.h3_text)\n",
    "                \n",
    "                if self.h3_text not in self.tr:\n",
    "                    self.tr[self.h3_text] = trset\n",
    "                    \n",
    "                    if self.h3_text not in self.trlog:\n",
    "                        self.trlog[self.h3_text] = dict()\n",
    "                        \n",
    "                    for s in trset:\n",
    "                        if s not in self.trlog[self.h3_text]:\n",
    "                            (self.trlog[self.h3_text])[s] = (self.banNo if self.banNo != '' else( self.brBanNo if  self.brBanNo != '' else self.estbId))\n",
    "                else:\n",
    "                    self.tr[self.h3_text] |= trset\n",
    "                    \n",
    "                \n",
    "                #del parser\n",
    "                \n",
    "                \n",
    "                self.random_sleep(scale = self.sleep_scale)\n",
    "            else:\n",
    "                item_count += self.pageItem\n",
    "                #self.this_round_time_end()\n",
    "                #self.this_round_exectime()\n",
    "                self.tasklog.log(mode='format', args=(self.exectime(), self.this_round_exectime(), self.pageNow, self.pageItem), postfix = 'page finished, total {: >6d} items'.format(item_count))\n",
    "                print('==================================================')\n",
    "                print('page', self.pageNow, 'total', item_count , ' time', self.exectime(), 'round time', self.this_round_exectime())\n",
    "                print('==================================================')\n",
    "\n",
    "\n",
    "                if item_count >= self.flush_threshold:\n",
    "                    #print('end of h3_info_collector', ' total: ', t, ' pages: ', p)\n",
    "                    print('end of h3_info_collector() pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "                    self.tasklog.log(mode='manual', in_log = 'end of h3_info_collector() pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "                    return\n",
    "       \n",
    "            \n",
    "    def second_page_not_found(self):\n",
    "        selector = etree.HTML(crawler.response.content)\n",
    "        texts = selector.xpath('//table/tr/td/table/tr/td/descendant::*/text()')\n",
    "        \n",
    "        clean_texts = list()\n",
    "        for t in texts:\n",
    "            #t = t.encode('latin_1', errors='ignore').decode('utf8', errors='ignore')\n",
    "            t = re.sub(r'\\s', r'', t)\n",
    "            if t:\n",
    "                clean_texts.append(t)\n",
    "        else:\n",
    "            if '很抱歉，您所存取的網頁系統暫時無法回應。' in clean_texts and '回上一頁' in clean_texts and '回首頁' in clean_texts:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "       \n",
    "    def output_files(self, itemStart, itemEnd):\n",
    "        d = datetime.now()\n",
    "        timestamp = \"{0:0>4d}{1:0>2d}{2:0>2d}_{3:0>2d}{4:0>2d}{5:0>2d}\".format(d.year,d.month,d.day,d.hour,d.minute,d.second)\n",
    "        fname = '{0:　>5s}@{1: >10s}-{2: >17s}'.format(self.qryCond, str(self.qryType[0]),timestamp)        \n",
    "        #fname = '{0:　>5s}@{1: >10s} [{2: >6d}-{3: >6d}][{4: >6d}-{5: >6d}]-{6: >17s}'.format(self.qryCond, str(self.qryType[0]), self.pageStart, self.pageEnd, itemStart, itemEnd,timestamp)        \n",
    "        for key in self.results:\n",
    "            if self.results[key]:\n",
    "                #j = json.dumps(self.results[key], ensure_ascii=False)\n",
    "                j = self.results[key]\n",
    "                #with open(fname+'_'+key+'_json.json', 'w') as jout:\n",
    "                #    json.dump(j, jout, ensure_ascii=False)\n",
    "                with open(self.total_json_name+'_json.json', 'a') as tjout:\n",
    "                    json.dump(j, tjout, ensure_ascii=False)\n",
    "                    tjout.write(',\\n')\n",
    "                \n",
    "                #with open(fname+'_'+key+'_json.pkl', 'wb') as jpklout:  \n",
    "                #    pickle.dump(j, jpklout)\n",
    "                    \n",
    "                #df = pd.DataFrame(self.results[key])\n",
    "                #with open(fname+'_'+key+'df.csv', 'w') as dfcsvout:\n",
    "                #    df.to_csv(dfcsvout, index=False)\n",
    "                #with open(fname+'_'+key+'df.pkl', 'wb') as dfpklout:\n",
    "                #    pickle.dump(j, dfpklout)\n",
    "                    \n",
    "                #with open(fname+'_'+key+'content.html', 'w') as contentout:\n",
    "                #    contentout.write(self.response.content.decode('utf8'))\n",
    "                #    #pickle.dump(self.response.content.decode('utf8'), contentout)\n",
    "                    \n",
    "    def set_pageStart(self, pageStart):\n",
    "        self.pageStart = pageStart\n",
    "\n",
    "    def set_pageEnd(self, pageEnd):\n",
    "        self.pageEnd = pageEnd\n",
    "\n",
    "\n",
    "        \n",
    "    def parse_and_gen_schema(self, pageStart=1, pageEnd=1): \n",
    "        self.set_pageStart(pageStart)\n",
    "        self.set_pageEnd(pageEnd)\n",
    "        \n",
    "        item_count = 0\n",
    "        item_last = 0\n",
    "        item_count_flush = 0\n",
    "        for self.pageNow in range(self.pageStart, self.pageEnd+1):\n",
    "            self.this_round_time_start()\n",
    "            #self.pageNow = p\n",
    "            if self.pageNow > 1:\n",
    "                self.set_form_data_url1(mode = 1, currentPage = self.pageNow)\n",
    "            else:\n",
    "                self.set_form_data_url1(mode = 0)\n",
    "              \n",
    "            # 在first_connection刷完一頁(20筆)，檢查一次是否超過self.proxy_tick，若是就關掉舊的session，並轉到proxy\n",
    "            self.proxy_monitor()\n",
    "            \n",
    "            # self.first_connection() 出問題時重試10次\n",
    "            retry = 0\n",
    "            while not self.first_connection():\n",
    "                if retry > 10:\n",
    "                    with open('skip_query.log', 'a') as skpf:\n",
    "                        skpf.write(self.qryCond+str(self.qryType)+'\\n')\n",
    "                    continue\n",
    "                \n",
    "                retry += 1\n",
    "                self.tasklog.log(mode='manual', in_log = 'first_connection() @ page{} failed, retry {} times'.format(self.pageNow, retry))\n",
    "                time.sleep(2)\n",
    "                \n",
    "            for self.pageItem, o in enumerate(self.oncontextmenu, 1):\n",
    "                #self.pageItem = i\n",
    "                self.get_banKey_objectId(o)\n",
    "                \n",
    "                retry = 0\n",
    "                # self.second_connection()\n",
    "                while not self.second_connection():\n",
    "                    if retry > 10:\n",
    "                        continue\n",
    "                    retry += 1\n",
    "                    self.tasklog.log(mode='manual', in_log = 'second_connection() @ page{}  item {} failed, retry {} times'.format(self.pageNow, self.pageItem, retry))\n",
    "                    time.sleep(10)\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                if self.second_page_not_found():\n",
    "                    # 如果第二層商登資料網頁不存在，跳過\n",
    "                    self.tasklog.log(mode='format', args=(self.exectime(), self.this_round_exectime(), self.pageNow, self.pageItem), postfix = 'second page not found')                    \n",
    "                    continue\n",
    "                \n",
    "                    \n",
    "                self.get_h3()\n",
    "                #parser = parser_cmpy_type(self.h3_query)\n",
    "                parser = self.parser[self.h3_query]\n",
    "                parser.init_data_schema()\n",
    "                # 改掉log的方式\n",
    "                parser.parser(self.response, \n",
    "                              {'banNo':str(self.banNo),\n",
    "                               'brBanNo':str(self.brBanNo),\n",
    "                               'banKey':str(self.banKey),\n",
    "                               'estbId':str(self.estbId),\n",
    "                               'objectId':str(self.objectId)},\n",
    "                              {'page':str(self.pageNow),\n",
    "                               'item':str(self.pageItem)})\n",
    "                \n",
    "                \n",
    "            \n",
    "                #self.end = time.time()\n",
    "                self.exectime(self.h3_query)\n",
    "                print(self.h3_query, parser.data_schema)             \n",
    "                #self.results[self.h3_query].append(parser.data_schema)\n",
    "                # add some task info\n",
    "\n",
    "                parser.data_schema['qryCond'] = self.qryCond\n",
    "                parser.data_schema['h3_query'] = self.h3_query\n",
    "                parser.data_schema['pageNow'] = self.pageNow\n",
    "                parser.data_schema['pageItem'] = self.pageItem\n",
    "                \n",
    "                self.results[self.h3_query].append( copy.deepcopy(parser.data_schema) )\n",
    "                #print(\"----------- self.results\")\n",
    "                #print(self.results)\n",
    "                #print(\"----------- self.results\")\n",
    "                self.tasklog.log(mode='format', args=(self.exectime(), self.this_round_exectime(), self.pageNow, self.pageItem), postfix = 'done') \n",
    "                self.random_sleep(scale = self.sleep_scale)\n",
    "                item_count += 1\n",
    "                item_count_flush += 1\n",
    "            else:\n",
    "                #item_count += self.pageItem\n",
    "                #self.this_round_exectime()\n",
    "                #self.this_round_time_end()\n",
    "                \n",
    "                self.tasklog.log(mode='format', args=(self.exectime(), self.this_round_exectime(), self.pageNow, self.pageItem), postfix = 'page finished, total {: >6d} items'.format(item_count))\n",
    "                #self.task_log(mode='manual', in_log='page ', self.pageNow, ' total ', t , ' totaltime ', self.exectime(), '\\n', self.this_round_exectime())\n",
    "                print('==================================================')\n",
    "                print('page', self.pageNow, 'total', item_count , ' time', self.exectime(), 'round time', self.this_round_exectime())\n",
    "                print('==================================================')\n",
    "                if item_count_flush >= self.flush_threshold:\n",
    "                    item_count_flush = 0\n",
    "                    \n",
    "                    self.output_files(item_last, item_count)\n",
    "                    print('flush results to pandas pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "                    self.tasklog.log(mode='manual', in_log = 'flush results to pandas pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "                    \n",
    "                    del self.results\n",
    "                    self.results = defaultdict(list)\n",
    "                    item_last = item_count\n",
    "                    #return\n",
    "                #self.results.append( (self.querytype, parser.data_schema) )\n",
    "                self.random_sleep(scale = self.sleep_scale)\n",
    "        else:\n",
    "            #self.output_files()\n",
    "            self.output_files(item_last, item_count)\n",
    "            print('flush results to pandas pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "            self.tasklog.log(mode='manual', in_log = 'flush results to pandas pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "\n",
    "            print('end of parse_and_gen_schema() pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "            self.tasklog.log(mode='manual', in_log = 'end of parse_and_gen_schema() pages:{} items:{}'.format(self.pageNow, item_count))\n",
    "            self.tasklog.log_flush()\n",
    "            \n",
    "            del self.results\n",
    "            self.results = defaultdict(list)\n",
    "            item_last = item_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "\n",
    "import copy\n",
    "\n",
    "class parser_cmpy_type:\n",
    "\n",
    "    # 公司基本資料\n",
    "    col_Cmpy=['統一編號', '公司狀況', '公司名稱', '資本總額(元)', '實收資本額(元)', '代表人姓名', \n",
    "              '公司所在地', '登記機關', '核准設立日期', '最後核准變更日期', '停業日期(起)', '停業日期(迄)',\n",
    "              '所營事業資料' ]\n",
    "    rule_Cmpy={\n",
    "        '統一編號':'rule0',\n",
    "        '公司狀況':'rule0',\n",
    "        '公司名稱':'rule0',\n",
    "        '資本總額(元)':'rule0',\n",
    "        '實收資本額(元)':'rule0',\n",
    "        '代表人姓名':'rule0',\n",
    "        '公司所在地':'rule0',\n",
    "        '登記機關':'rule0',\n",
    "        '核准設立日期':'rule0',\n",
    "        '最後核准變更日期':'rule0',\n",
    "        '停業日期(起)':'rule0',\n",
    "        '停業日期(迄)':'rule0',\n",
    "        '所營事業資料':'rule5'\n",
    "    }\n",
    "    col_Cmpy_Shareholder=['序號','職稱','姓名','所代表法人','持有股份數']\n",
    "    col_Cmpy_Mgr=[]\n",
    "    col_Cmpy_BrCmpy=['序號','統一編號','分公司名稱','公司狀況','分公司核准設立日期','最後核准變更日期']\n",
    "    \n",
    "    # 外國公司報備基本資料\n",
    "    col_CmpyFrgnRp=['統一編號', '公司狀況', '公司名稱', '訴訟及非訴訟代理人姓名', '辦事處所在地', '登記機關',\n",
    "                    '核准設立日期', '最後核准變更日期', '代表人在中華民國境內所為的法律行為']    \n",
    "    rule_CmpyFrgnRp={\n",
    "        '統一編號':'rule0',\n",
    "        '公司狀況':'rule0',\n",
    "        '公司名稱':'rule0',\n",
    "        '訴訟及非訴訟代理人姓名':'rule0',\n",
    "        '辦事處所在地':'rule0',\n",
    "        '登記機關':'rule0',\n",
    "        '核准設立日期':'rule0',# 會有空值 <td></td>\n",
    "        '最後核准變更日期':'rule0',# 會有空值 <td></td>\n",
    "        '代表人在中華民國境內所為的法律行為':'rule0'\n",
    "        #'所營事業資料':'rule5'\n",
    "    }\n",
    "\n",
    "    # 外國公司認許基本資料\n",
    "    col_CmpyFrgn=['統一編號', '公司狀況', '公司名稱', '在中華民國境內營運資金', '訴訟及非訴訟代理人姓名', '分公司所在地',\n",
    "                  #'公司所在地', \n",
    "                  '登記機關', '核准設立日期', '最後核准變更日期', '停業日期(起)', '停業日期(迄)', '所營事業資料']\n",
    "    rule_CmpyFrgn={\n",
    "        '統一編號':'rule0',\n",
    "        '公司狀況':'rule0',# 處理跨<br>串字，<br>後面可能是空字串\n",
    "        '公司名稱':'rule0',\n",
    "        '在中華民國境內營運資金':'rule0',\n",
    "        '訴訟及非訴訟代理人姓名':'rule0',\n",
    "        '分公司所在地':'rule0',\n",
    "        #'公司所在地':'rule0',\n",
    "        '登記機關':'rule0',\n",
    "        '核准設立日期':'rule0',\n",
    "        '最後核准變更日期':'rule0', # <td></td>\n",
    "        '停業日期(起)':'rule0',\n",
    "        '停業日期(迄)':'rule0',\n",
    "        '所營事業資料':'rule5'\n",
    "    }\n",
    "    col_CmpyFrgn_BrCmpy=['序號','統一編號','分公司名稱','公司狀況','分公司核准設立日期','最後核准變更日期']\n",
    "\n",
    "\n",
    "    \n",
    "    # 大陸公司許可報備基本資料\n",
    "    col_CmpyCnRp=['統一編號', '公司狀況', '股權狀況', '公司名稱', '訴訟及非訴訟代理人姓名', '辦事處所在地',\n",
    "                  '登記機關', '核准設立日期', '最後核准變更日期', '代表人在台灣地區業務活動範圍']    \n",
    "    rule_CmpyCnRp={\n",
    "        '統一編號':'rule0',\n",
    "        '公司狀況':'rule0',\n",
    "        '股權狀況':'rule0',\n",
    "        '公司名稱':'rule0',# 有<br>串起來\n",
    "        '訴訟及非訴訟代理人姓名':'rule0',\n",
    "        '辦事處所在地':'rule0',\n",
    "        '登記機關':'rule0',\n",
    "        '核准設立日期':'rule0',\n",
    "        '最後核准變更日期':'rule0',\n",
    "        '代表人在台灣地區業務活動範圍':'rule0'\n",
    "        #'所營事業資料':'rule5'\n",
    "    }\n",
    "    \n",
    "    col_CmpyCnRp_BrCmpy=['序號','統一編號','分公司名稱','公司狀況','分公司核准設立日期','最後核准變更日期']\n",
    "\n",
    "\n",
    "\n",
    "    # 大陸公司許可基本資料\n",
    "    col_CmpyCn=['統一編號', '公司狀況', '股權狀況', '公司名稱', '在台灣地區營業所用', '訴訟及非訴訟代理人姓名', \n",
    "                '分公司所在地', #'公司所在地', \n",
    "                '登記機關', '核准設立日期', '最後核准變更日期', \n",
    "                #'停業日期(起)', '停業日期(迄)', \n",
    "                '所營事業資料']\n",
    "    rule_CmpyCn={\n",
    "        '統一編號':'rule0',\n",
    "        '公司狀況':'rule0',\n",
    "        '股權狀況':'rule0',\n",
    "        '公司名稱':'rule0',# 有<br>串起來\n",
    "        '在台灣地區營業所用':'rule0',\n",
    "        '訴訟及非訴訟代理人姓名':'rule0',\n",
    "        '分公司所在地':'rule0',\n",
    "        #'公司所在地':'null',\n",
    "        '登記機關':'rule0',\n",
    "        '核准設立日期':'rule0',\n",
    "        '最後核准變更日期':'rule0',\n",
    "        #'停業日期(起)':'null',\n",
    "        #'停業日期(迄)':'null',\n",
    "        '所營事業資料':'rule5'\n",
    "    }\n",
    "    col_CmpyCn_BrCmpy=['序號','統一編號','分公司名稱','公司狀況','分公司核准設立日期','最後核准變更日期']\n",
    "    \n",
    "    # 分公司資料\n",
    "    col_BrCmpy=['分公司統一編號', '分公司狀況', '分公司名稱', '分公司經理姓名', '分公司所在地', '核准設立日期', \n",
    "                #'廢止日期', \n",
    "                '最後核准變更日期', '總(本)公司統一編號', '總(本)公司名稱']\n",
    "    rule_BrCmpy={\n",
    "        '分公司統一編號':'rule0',\n",
    "        '分公司狀況':'rule0',\n",
    "        '分公司名稱':'rule0',\n",
    "        '分公司經理姓名':'rule0',\n",
    "        '分公司所在地':'rule0',\n",
    "        '核准設立日期':'rule0',\n",
    "        #'廢止日期':'rule0',\n",
    "        '最後核准變更日期':'rule0',\n",
    "        '總(本)公司統一編號':'rule1', # <br><a></a></br>\n",
    "        '總(本)公司名稱':'rule1' # <br><a>\"雙\"<img>\"有限公司\"</a></br>要處理未識別字有圖的狀況\n",
    "    }\n",
    "    \n",
    "    # 商業登記基本資料\n",
    "    col_Busm=['登記機關', '商業統一編號', '核准設立日期', '最近異動日期', '商業名稱', '負責人姓名',\n",
    "              '負責人姓名-出資額(元)', '現況', '資本額(元)', '組織類型', '地址', '營業項目']\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    <tr>\n",
    "    <td class=\"txt_td\">負責人姓名</td>\n",
    "        <td>\n",
    "            <table style=\"width:100%\">\n",
    "                <tbody><tr>\n",
    "                    <td width=\"50%\">蔡培火</td>         rule21\n",
    "                    <td width=\"50%\">出資額(元):0</td>   rule22\n",
    "                </tr></tbody></table>\n",
    "        </td>\n",
    "    </tr>\n",
    "    \"\"\"\n",
    "    \n",
    "    rule_Busm={\n",
    "        '登記機關':'rule0',\n",
    "        '商業統一編號':'rule0', # 可能只有訂閱鈕\n",
    "        '核准設立日期':'rule0', \n",
    "        '最近異動日期':'rule0',\n",
    "        '商業名稱':'rule0', # <td><a>\"雙\"<img>\"有限公司\"</a></td>要處理未識別字有圖的狀況\n",
    "        '負責人姓名':'rule2',\n",
    "        '負責人姓名-出資額(元)':'rule2',# 出資額(元):0 \n",
    "        '合夥人姓名':'rule2',\n",
    "        '合夥人姓名-出資額(元)':'rule2',\n",
    "        '現況':'rule0',\n",
    "        '資本額(元)':'rule0',\n",
    "        '組織類型':'rule0',\n",
    "        '地址':'rule0',\n",
    "        '營業項目':'rule5' # 各種金紙冥紙等有關祭拜用品零售買賣（炮竹除外）@@\n",
    "    }\n",
    "    col_Busm_BrBusm=['分支機構統一編號','分支機構名稱','分支機構地址','分支機構經理人姓名'] \n",
    "    \n",
    "    # 商業登記基本資料(分支機構)\n",
    "    col_BrBusm=['分支機構登記機關', '分支機構統一編號', '核准設立日期', '最近異動日期', '分支機構名稱', '分支機構經理人姓名', \n",
    "                '分支機構現況', '分支機構地址', '總機構統一編號', '總(本)商業名稱']\n",
    "    rule_BrBusm={'分支機構登記機關':'rule0', \n",
    "                 '分支機構統一編號':'rule0', \n",
    "                 '核准設立日期':'rule0',\n",
    "                 '最近異動日期':'rule0',\n",
    "                 '分支機構名稱':'rule0',\n",
    "                 '分支機構經理人姓名':'rule0',\n",
    "                 '分支機構現況':'rule0',\n",
    "                 '分支機構地址':'rule0', \n",
    "                 '總機構統一編號':'rule1',\n",
    "                 '總(本)商業名稱':'rule1'}\n",
    "    \n",
    "    # 工廠基本資料\n",
    "    col_Fact=['登記機關', '工廠名稱', '工廠登記編號', '工廠登記核准日期', '工廠設立許可案號', '工廠設立核准日期', \n",
    "              '工廠地址', '工廠負責人姓名', '公司(營利事業)統一編號', '工廠組織型態', '工廠資本額', '工廠登記狀態',\n",
    "              '最後核准變更日期', '工廠設立許可廢止核准日期', '工廠登記歇業核准日期', '工廠登記廢止核准日期', '工廠登記公告廢止核准日期', '最近一次校正年度', \n",
    "              '最近一次校正結果', '依據行政院主計處『中華民國行業標準分類』100年3月第9次修訂', '產業類別', '主要產品']\n",
    "    rule_Fact={\n",
    "        '登記機關':'rule0',\n",
    "        '工廠名稱':'rule0',\n",
    "        '工廠登記編號':'rule0',\n",
    "        '工廠登記核准日期':'rule0',\n",
    "        '工廠設立許可案號':'rule0',\n",
    "        '工廠設立核准日期':'rule0',\n",
    "        '工廠地址':'rule0',\n",
    "        '工廠負責人姓名':'rule0',\n",
    "        '公司(營利事業)統一編號':'rule0',\n",
    "        '工廠組織型態':'rule0',\n",
    "        '工廠資本額':'rule0',\n",
    "        '工廠登記狀態':'rule0',\n",
    "        '最後核准變更日期':'rule0',\n",
    "        '工廠設立許可廢止核准日期':'rule0',\n",
    "        '工廠登記歇業核准日期':'rule0',\n",
    "        '工廠登記廢止核准日期':'rule0',\n",
    "        '工廠登記公告廢止核准日期':'rule0',\n",
    "        '最近一次校正年度':'rule0',\n",
    "        '最近一次校正結果':'rule0',\n",
    "        '依據行政院主計處『中華民國行業標準分類』100年3月第9次修訂':'rule0', # 這個tr是有<br>的\n",
    "        #'依據行政院主計處『中華民國行業標準分類』':'null',\n",
    "        '產業類別':'rule5', # 單一項最後面有<br>\n",
    "        '主要產品':'rule5'\n",
    "    }\n",
    "    # 有限合夥登記基本資料\n",
    "    col_Lmtd=['登記機關', '統一編號', '有限合夥名稱', '所在地', '實收出資額(元)', '核准設立日期', '現況', \n",
    "              '存續期間', '最近一次登記狀況核准日期及文號', '代表人姓名', '代表人姓名-出資額(元)', '普通合夥人姓名-責任類型', '普通合夥人姓名',\n",
    "              '普通合夥人姓名-出資額(元)', '普通合夥人姓名-責任類型', '有限合夥人', '有限合夥人-出資額(元)', '有限合夥人-責任類型', '經理人姓名',\n",
    "              '約定解散事由', '所營事業項目']\n",
    "    rule_Lmtd={\n",
    "        '登記機關':'rule0',\n",
    "        '統一編號':'rule0',\n",
    "        '有限合夥名稱':'rule0',\n",
    "        '所在地':'rule0',\n",
    "        '實收出資額(元)':'rule0',\n",
    "        '核准設立日期':'rule0',\n",
    "        '現況':'rule0',\n",
    "        '存續期間':'rule0',\n",
    "        '最近一次登記狀況核准日期及文號':'rule0',# 標題有用<br>隔開\n",
    "        '代表人姓名':'rule2',\n",
    "        '代表人姓名-出資額(元)':'rule2',\n",
    "        '代表人姓名-責任類型':'rule2',\n",
    "        '普通合夥人姓名':'rule2',\n",
    "        '普通合夥人姓名-出資額(元)':'rule2',\n",
    "        '普通合夥人姓名-責任類型':'rule2',\n",
    "        '有限合夥人':'rule2',\n",
    "        '有限合夥人-出資額(元)':'rule2',\n",
    "        '有限合夥人-責任類型':'rule2',\n",
    "        '經理人姓名':'rule0',\n",
    "        '約定解散事由':'rule0',\n",
    "        '所營事業項目':'rule5'\n",
    "    }\n",
    "    col_Lmtd_BrBusm=['分支機構統一編號','分支機構名稱','分支機構地址','分支機構經理人姓名']\n",
    "    \n",
    "    # 有限合夥登記基本資料(分支機構)\n",
    "    col_BrLmtd=['登記機關', '統一編號', '分支機構名稱', '所在地', '在中華民國境內營運資金', '核准設立日期', \n",
    "                '登記狀況', '最近一次登記狀況核准日期及文號', '在中華民國境內負責人', '分支機構經理人', '所營事業項目', \n",
    "                '本機構統一編號', '本機構名稱']\n",
    "    rule_BrLmtd={\n",
    "        '登記機關':'rule0',\n",
    "        '統一編號':'rule0',\n",
    "        '分支機構名稱':'rule0',\n",
    "        '所在地':'rule0',\n",
    "        '在中華民國境內營運資金':'rule0',\n",
    "        '核准設立日期':'rule0',\n",
    "        '登記狀況':'rule0',\n",
    "        '最近一次登記狀況核准日期及文號':'rule0',# 標題有用<br>隔開\n",
    "        '在中華民國境內負責人':'rule0',\n",
    "        '分支機構經理人':'rule0',\n",
    "        '所營事業項目':'rule5',\n",
    "        '本機構統一編號':'rule0',\n",
    "        '本機構名稱':'rule0'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    col_book = {'Cmpy':col_Cmpy, \n",
    "                'CmpyFrgnRp':col_CmpyFrgnRp, \n",
    "                'CmpyFrgn':col_CmpyFrgn, \n",
    "                'CmpyCnRp':col_CmpyCnRp, \n",
    "                'CmpyCn':col_CmpyCn, \n",
    "                'BrCmpy':col_BrCmpy, \n",
    "                'Busm':col_Busm, \n",
    "                'BrBusm':col_BrBusm, \n",
    "                'Fact':col_Fact, \n",
    "                'Lmtd':col_Lmtd, \n",
    "                'BrLmtd':col_BrLmtd}\n",
    "    \n",
    "    col_sub_book = {'Cmpy':[col_Cmpy_Shareholder, col_Cmpy_Mgr, col_Cmpy_BrCmpy],\n",
    "                    'CmpyFrgnRp':[], \n",
    "                    'CmpyFrgn':[col_CmpyFrgn_BrCmpy], \n",
    "                    'CmpyCnRp':[col_CmpyCnRp_BrCmpy], \n",
    "                    'CmpyCn':[col_CmpyCn_BrCmpy], \n",
    "                    'BrCmpy':[], \n",
    "                    'Busm':[col_Busm_BrBusm], \n",
    "                    'BrBusm':[], \n",
    "                    'Fact':[], \n",
    "                    'Lmtd':[col_Lmtd_BrBusm], \n",
    "                    'BrLmtd':col_BrLmtd}\n",
    "    \n",
    "    rule_book = {'Cmpy':rule_Cmpy, \n",
    "                 'CmpyFrgnRp':rule_CmpyFrgnRp, \n",
    "                 'CmpyFrgn':rule_CmpyFrgn, \n",
    "                 'CmpyCnRp':rule_CmpyCnRp, \n",
    "                 'CmpyCn':rule_CmpyCn, \n",
    "                 'BrCmpy':rule_BrCmpy, \n",
    "                 'Busm':rule_Busm, \n",
    "                 'BrBusm':rule_BrBusm, \n",
    "                 'Fact':rule_Fact, \n",
    "                 'Lmtd':rule_Lmtd, \n",
    "                 'BrLmtd':rule_BrLmtd}\n",
    "    \n",
    "    \n",
    "    def __init__(self, h3_query, tasklog):\n",
    "        #self.table_to_db = parser_cmpy_type.table_to_db_assign[cmpy_type]\n",
    "        self.h3_query = h3_query\n",
    "        self.tr_rule = parser_cmpy_type.rule_book[self.h3_query]        \n",
    "        self.data_schema = dict()\n",
    "        self.td_rule_handler = {\n",
    "            'rule0'   :self.rule0,\n",
    "            'rule1'   :self.rule1,\n",
    "            'rule2'   :self.rule2,\n",
    "            #'rule3'   :self.special_rule3,\n",
    "            #'rule4'   :self.special_rule4,\n",
    "            'rule5'   :self.rule5,\n",
    "        }\n",
    "        self.tasklog = tasklog\n",
    "        \n",
    "    def init_data_schema(self):\n",
    "        self.data_schema = dict()\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.encode('latin_1', errors='ignore').decode('utf8', errors='ignore')\n",
    "        text = re.sub(r'\\s', r'', text)\n",
    "        text = re.sub(r'[「」]',r'', text)\n",
    "        return text\n",
    "        \n",
    "    def clean_Minguo_calendar(self, text):\n",
    "        #if text is None or not text:\n",
    "        if text is None or not len(text):\n",
    "            return \"\"\n",
    "            \n",
    "        text_year = text.split('年')[0]\n",
    "        text_month = text.split('年')[1].split('月')[0]\n",
    "        text_day = text.split('年')[1].split('月')[1].replace('日','')\n",
    "        text_year = str(int(text_year) + 1911)\n",
    "        return \"{}-{}-{}\".format(text_year, text_month, text_day)\n",
    "    \n",
    "    def td_remove_br(self, td):\n",
    "        \"\"\"\n",
    "        preprocess ./tr/td, remove <br> between text()\n",
    "        \"\"\"\n",
    "        if td is None:\n",
    "            return \"\"\n",
    "        \n",
    "        tds = td.xpath('./td')\n",
    "        text = list()\n",
    "        for t in td.xpath('./text()'):\n",
    "            t = t.encode('latin_1', errors='ignore').decode('utf8', errors='ignore')\n",
    "            t = re.sub(r'\\s', r'', t)\n",
    "            if t:\n",
    "                text.append(t)\n",
    "        #print(''.join(text))\n",
    "        \n",
    "        return ''.join(text)\n",
    "                        \n",
    "        \n",
    "    def get_td_text(self, td, sp='', rule=0):\n",
    "        import re\n",
    "        \"\"\"\n",
    "        get td text from type A cell:\n",
    "        <td class=\"txt_td\">\n",
    "            \"最近一次登記狀況\"\n",
    "            <br>\n",
    "            \"核准日期及文號\"\n",
    "        </td>\n",
    "        \n",
    "        get td text from type B cell:\n",
    "        <td>\n",
    "            \"\n",
    "                    大陸商中國銀行股份有限公司(在臺灣地區公司名稱)\n",
    "            \"\n",
    "            <span>Google搜尋</span>\n",
    "            <br>\n",
    "            \"\n",
    "                中國銀行股份有限公司　　　(在大陸地區公司名稱)\n",
    "            \"\n",
    "            <span id=\"linkMoea\">\n",
    "                <span>\n",
    "                    \"「\"\n",
    "                    <span>廠商英文名稱查詢(限經營出進口或買賣業務者)</span>\n",
    "                    \"」\"\n",
    "                    <div> ... </div>\n",
    "                </span>\n",
    "            </span>\n",
    "        </td>\n",
    "        \n",
    "        get td text from type C cell:\n",
    "        <td>\n",
    "            \"\n",
    "                084\n",
    "                食用油脂\n",
    "            \"\n",
    "            <br>\n",
    "            \"\n",
    "                089\n",
    "                其他食品\n",
    "            \"\n",
    "            <br>\n",
    "        </td>        \n",
    "        \"\"\"\n",
    "\n",
    "        if td is None:\n",
    "            return \"\"\n",
    "        \n",
    "        if rule == 0:\n",
    "            nodes = td.xpath('./text()')\n",
    "        elif rule == 1:\n",
    "            nodes = td.xpath('./descendant::text()')\n",
    "        elif rule == 5:\n",
    "            nodes = td.xpath('./text()')            \n",
    "        \n",
    "        text = list()\n",
    "        for t in nodes:\n",
    "            if t:\n",
    "                t = self.clean_text(t)\n",
    "                text.append(t)\n",
    "        else:\n",
    "            # 有時<br>後會是空字串，濾掉空字串\n",
    "            return sp.join([t for t in text if t])\n",
    "        \n",
    "    def rule0(self, td):\n",
    "        return self.get_td_text(td, sp = '+', rule=0)\n",
    "    \n",
    "    def rule1(self, td):\n",
    "        return self.get_td_text(td, sp = '', rule=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def rule2(self, td, key):\n",
    "        items = list()\n",
    "        trs = td.xpath('./table/tr')\n",
    "        for i, tr in enumerate(trs):\n",
    "            texts = tr.xpath('./td/text()')\n",
    "            item = dict()\n",
    "            for t in texts:\n",
    "                t = self.clean_text(t)\n",
    "                sub_item = t.split(':')\n",
    "                if len(sub_item) == 1:\n",
    "                    item[key]=sub_item[0]\n",
    "                else:\n",
    "                    k, v = sub_item\n",
    "                    item[k]=v\n",
    "            else:\n",
    "                items.append(item)\n",
    "                \n",
    "        return items\n",
    "        \n",
    "    def rule5(self, td):\n",
    "        rule5_str = self.get_td_text(td, sp = '+', rule=5)\n",
    "        \n",
    "        return rule5_str\n",
    "    \n",
    "    \n",
    "    def retrive_tr(self, res, trcheck, info1, info2):\n",
    "        selector = etree.HTML(res.content)\n",
    "        divs = selector.xpath('//div[@class=\"tab-content\"]/div')\n",
    "        div0 = divs[0]\n",
    "        trs = div0.xpath('./div[@class=\"table-responsive\"]/table[@class=\"table table-striped\"]/tbody/tr')\n",
    "        \n",
    "        trset = set()\n",
    "        for tr in trs:\n",
    "            tds = tr.xpath('./td')\n",
    "            td0 = tds[0]\n",
    "            key = self.get_td_text(td0)\n",
    "            \n",
    "            if key not in trcheck:\n",
    "                self.tasklog.log(mode = 'manual', in_log = self.logstr('new_tr', info1, info2))\n",
    "            \n",
    "            trset.add(key)        \n",
    "        return trset\n",
    "    \n",
    "    def logstr(self, mode, info1, info2):\n",
    "        info1_str = ' '.join([k+' '+v for k, v in list(info1.items())])\n",
    "        info2_str = ' '.join(['page', info2['page'], 'item', info2['item']])\n",
    "        return ' '.join([mode, '@', info2_str, 'where', info1_str])\n",
    "    \n",
    "    def parser(self, res, info1, info2):\n",
    "        selector = etree.HTML(res.content)\n",
    "        divs = selector.xpath('//div[@class=\"tab-content\"]/div')\n",
    "        div0 = divs[0]\n",
    "        trs = div0.xpath('./div[@class=\"table-responsive\"]/table[@class=\"table table-striped\"]/tbody/tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.xpath('./td')\n",
    "\n",
    "            td0 = tds[0]\n",
    "            key = self.get_td_text(td0)\n",
    "            # 解析出來的tr若只有一欄，不需要解譯\n",
    "            if len(tds) > 1:\n",
    "                # 先拿第一個td\n",
    "                td1 = tds[1]\n",
    "                \n",
    "                # 如果tr的項目名稱不在預設的欄位，將它擴充(預設rule0)，記得要處理col_book跟rule_book\n",
    "                if key not in parser_cmpy_type.col_book[self.h3_query]:\n",
    "                    parser_cmpy_type.col_book[self.h3_query].append(key)\n",
    "                    td1_first_child = td1.xpath('./child::*')\n",
    "                    if len(td1_first_child) == 0:\n",
    "                        (parser_cmpy_type.rule_book[self.h3_query])[key] = 'rule0'\n",
    "                    elif td1_first_child[0].tag == 'table':\n",
    "                        (parser_cmpy_type.rule_book[self.h3_query])[key] = 'rule2'\n",
    "                    elif td1_first_child[0].tag == 'a':\n",
    "                        (parser_cmpy_type.rule_book[self.h3_query])[key] = 'rule1'\n",
    "                    else:\n",
    "                        (parser_cmpy_type.rule_book[self.h3_query])[key] = 'rule0'\n",
    "                        \n",
    "\n",
    "                    # 做個log\n",
    "                    #self.log('new_tr', info1, info2)\n",
    "                    self.tasklog.log(mode = 'manual', in_log = self.logstr('new_tr', info1, info2))\n",
    "                \n",
    "                # 解譯 \n",
    "                \n",
    "                rule = self.tr_rule[key]\n",
    "                if rule == 'rule2':\n",
    "                    value = self.td_rule_handler[rule](td1, key)\n",
    "                    self.data_schema[key] = value\n",
    "                    #for key, value in items:\n",
    "                    #    self.data_schema[key] = value\n",
    "                    #    (parser_cmpy_type.rule_book[self.h3_query])[key] = 'rule2'\n",
    "                              \n",
    "                else:\n",
    "                    value = self.td_rule_handler[rule](td1)\n",
    "                    self.data_schema[key] = value\n",
    "                    \n",
    "            # 只有一個tr的做個log\n",
    "            else:\n",
    "                # 寫個information\n",
    "                #self.log('single_col_tr', info1, info2)\n",
    "                self.tasklog.log(mode = 'manual', in_log = self.logstr('single_col_tr', info1, info2))\n",
    "                \n",
    "        else:\n",
    "            self.data_schema['update_time'] = time.strftime('%Y/%m/%d %H:%M:%S', time.localtime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "import pickle\n",
    "import proxypool\n",
    "# usage:\n",
    "# cralwer_v10.py 3        /usr/local/bin/phantomjs 60005            3\n",
    "#                job號碼   phontomjs執行檔位置        查詢流水號，可接關  proxy_tick\n",
    "\n",
    "tasknum = sys.argv[1]\n",
    "path_phantomjs = sys.argv[2]\n",
    "\n",
    "\n",
    "#tasknum = 1\n",
    "#path_phantomjs = '/usr/local/Cellar/phantomjs/2.1.1/bin/phantomjs'\n",
    "\n",
    "\n",
    "\n",
    "task_dir = './task_ini/'\n",
    "task = pickle.load(open(task_dir+'instance-g{}_v10.x2_job.pkl'.format(tasknum), 'rb'))\n",
    "taskstart = int(sys.argv[3]) if len(sys.argv) >= 4 else int(task[0][0])\n",
    "#proxy_tick = int(sys.argv[4]) if len(sys.argv) >= 5 else 1\n",
    "\n",
    "#taskstart = 0\n",
    "#proxy_tick = 20\n",
    "\n",
    "#config['TASK']['1']\n",
    "#task_proxy = proxypool.proxypool(path_phantomjs = path_phantomjs)\n",
    "#task_proxy.proxy_set_max = 100\n",
    "#task_proxy.world_proxy()\n",
    "\n",
    "crawler = cmpyinfo_crawler(path_phantomjs = path_phantomjs, logname='instance{}_v10.x2_job.log'.format(tasknum), sleep_scale='none')\n",
    "crawler.proxypool.proxy_set_max = 150\n",
    "crawler.proxypool.group_proxy()\n",
    "#crawler.proxy_tick = proxy_tick\n",
    "crawler.proxypool.none_freq = 4\n",
    "\n",
    "#crawler.qryCond = t[1]\n",
    "#crawler.qryType = t[2]\n",
    "#crawler.pageStart = t[3]\n",
    "#crawler.pageEnd = t[4]\n",
    "\n",
    "for t in task:\n",
    "\n",
    "    \n",
    "    crawler.qryCond = t[1]\n",
    "    crawler.qryType = t[2]\n",
    "    crawler.pageStart = t[3]\n",
    "    crawler.pageEnd = t[4]\n",
    "    if int(t[0]) < taskstart:\n",
    "        continue\n",
    "        \n",
    "    print(\"======================================\")\n",
    "    print(\"task \", t[0], \": \", t[1], \"@\", t[2])\n",
    "    print(\"======================================\")\n",
    "    \n",
    "    crawler.search_error_cnt = 0\n",
    "    crawler.set_form_data_url1(mode = 0, currentPage = 1)\n",
    "    while not crawler.first_connection() and crawler.search_error_cnt < 6:\n",
    "        crawler.change_proxy()\n",
    "\n",
    "    if not crawler.search_error_cnt < 6:\n",
    "        crawler.search_error_cnt = 0\n",
    "        continue\n",
    "    crawler.search_error_cnt = 0\n",
    "    #time.sleep(random.choice([5,5.5,6,7,10,3,5,4,7,7,1]))\n",
    "    crawler.resolve_page()\n",
    "    crawler.parse_and_gen_schema(1, crawler.totalPage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
